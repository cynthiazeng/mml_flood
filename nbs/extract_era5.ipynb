{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERA5 Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youngoh/Desktop/flood_urop_repo/mml_flood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youngoh/Desktop/flood_urop_repo/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import ee \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project='my-project-410920') ### YOUR PROJECT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_extract = ['temperature_2m', 'total_precipitation_sum', 'u_component_of_wind_10m',\n",
    "\t\t\t\t\t\t'v_component_of_wind_10m', 'surface_pressure', 'snowfall_sum',\n",
    "\t\t\t\t\t\t'snowmelt_sum', 'dewpoint_temperature_2m',\n",
    "    \t\t\t\t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_df_sub1 = pd.read_csv('data/testing/x_stat.csv')\n",
    "y_master = pd.read_csv('data/testing/y_master.csv')\n",
    "n_pred = 1\n",
    "# lookup = pd.read_csv('lookup.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_target(x_df, y_master, disaster, next_n):\n",
    "    \"\"\"\n",
    "    Attach a 'target' column to x_df based on disaster data in y_master.\n",
    "    If no data exists in y_master for a given grid_id and year, set the target to NaN.\n",
    "    Look up from next 1 to next_n years, if there is a major flood occuring.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_df = x_df.copy()\n",
    "    # Create a dictionary for fast lookup: {(grid_id, year): disaster_value}\n",
    "    disaster_lookup = {\n",
    "        (row['grid_id'], row['year']): row[disaster+'_bin']\n",
    "        for _, row in y_master.iterrows()\n",
    "    }\n",
    "\n",
    "    # Initialize a 'target' column in x_df\n",
    "    target_col = 'target_' + disaster + '_' + str(next_n)\n",
    "    x_df[target_col] = np.nan  # Default to NaN\n",
    "\n",
    "    # Iterate over x_df rows\n",
    "    for idx, row in x_df.iterrows():\n",
    "        grid_id = row['grid_id']\n",
    "        year = row['year']\n",
    "\n",
    "        # Check if (grid_id, year + next_n + 1) exists in y_master\n",
    "        if (grid_id, year + next_n ) not in disaster_lookup:\n",
    "            # No data found for (grid_id, year + next_n + 1), skip this row\n",
    "            continue\n",
    "\n",
    "        # Check years from year+1 to year+next_n\n",
    "        target_found = 0\n",
    "        for i in range(1, next_n + 1):\n",
    "            future_year = year + i\n",
    "            if disaster_lookup.get((grid_id, future_year), 0) == 1:\n",
    "                target_found = 1\n",
    "                break\n",
    "\n",
    "        # Update the 'target' column\n",
    "        x_df.at[idx, target_col] = target_found\n",
    "    # Drop rows where 'target' is NaN\n",
    "    x_df = x_df.dropna(subset=[target_col])\n",
    "\n",
    "    return x_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>stat_flood_amt</th>\n",
       "      <th>stat_storm_amt</th>\n",
       "      <th>stat_earthquake_amt</th>\n",
       "      <th>stat_extreme temperature _amt</th>\n",
       "      <th>stat_landslide_amt</th>\n",
       "      <th>stat_volcanic activity_amt</th>\n",
       "      <th>stat_drought_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>stat_storm_bin</th>\n",
       "      <th>stat_earthquake_bin</th>\n",
       "      <th>stat_extreme temperature _bin</th>\n",
       "      <th>stat_landslide_bin</th>\n",
       "      <th>stat_volcanic activity_bin</th>\n",
       "      <th>stat_drought_bin</th>\n",
       "      <th>stat_mass movement (dry)_bin</th>\n",
       "      <th>stat_lat</th>\n",
       "      <th>stat_lon</th>\n",
       "      <th>target_flood_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48964</th>\n",
       "      <td>48964</td>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48965</th>\n",
       "      <td>48965</td>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48966</th>\n",
       "      <td>48966</td>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48967</th>\n",
       "      <td>48967</td>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48968</th>\n",
       "      <td>48968</td>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48140 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     grid_id  year  stat_flood_amt  stat_storm_amt  \\\n",
       "0               0  (-46, 168)  1960             0.0             0.0   \n",
       "1               1  (-46, 168)  1961             0.0             0.0   \n",
       "2               2  (-46, 168)  1962             0.0             0.0   \n",
       "3               3  (-46, 168)  1963             0.0             0.0   \n",
       "4               4  (-46, 168)  1964             0.0             0.0   \n",
       "...           ...         ...   ...             ...             ...   \n",
       "48964       48964   (66, 130)  2013             0.0             0.0   \n",
       "48965       48965   (66, 130)  2014             0.0             0.0   \n",
       "48966       48966   (66, 130)  2015             0.0             0.0   \n",
       "48967       48967   (66, 130)  2016             0.0             0.0   \n",
       "48968       48968   (66, 130)  2017             0.0             0.0   \n",
       "\n",
       "       stat_earthquake_amt  stat_extreme temperature _amt  stat_landslide_amt  \\\n",
       "0                      0.0                            0.0                 0.0   \n",
       "1                      0.0                            0.0                 0.0   \n",
       "2                      0.0                            0.0                 0.0   \n",
       "3                      0.0                            0.0                 0.0   \n",
       "4                      0.0                            0.0                 0.0   \n",
       "...                    ...                            ...                 ...   \n",
       "48964                  0.0                            0.0                 0.0   \n",
       "48965                  0.0                            0.0                 0.0   \n",
       "48966                  0.0                            0.0                 0.0   \n",
       "48967                  0.0                            0.0                 0.0   \n",
       "48968                  0.0                            0.0                 0.0   \n",
       "\n",
       "       stat_volcanic activity_amt  stat_drought_amt  ...  stat_storm_bin  \\\n",
       "0                             0.0               0.0  ...             0.0   \n",
       "1                             0.0               0.0  ...             0.0   \n",
       "2                             0.0               0.0  ...             0.0   \n",
       "3                             0.0               0.0  ...             0.0   \n",
       "4                             0.0               0.0  ...             0.0   \n",
       "...                           ...               ...  ...             ...   \n",
       "48964                         0.0               0.0  ...             0.0   \n",
       "48965                         0.0               0.0  ...             0.0   \n",
       "48966                         0.0               0.0  ...             0.0   \n",
       "48967                         0.0               0.0  ...             0.0   \n",
       "48968                         0.0               0.0  ...             0.0   \n",
       "\n",
       "       stat_earthquake_bin  stat_extreme temperature _bin  stat_landslide_bin  \\\n",
       "0                      0.0                            0.0                 0.0   \n",
       "1                      0.0                            0.0                 0.0   \n",
       "2                      0.0                            0.0                 0.0   \n",
       "3                      0.0                            0.0                 0.0   \n",
       "4                      0.0                            0.0                 0.0   \n",
       "...                    ...                            ...                 ...   \n",
       "48964                  0.0                            0.0                 0.0   \n",
       "48965                  0.0                            0.0                 0.0   \n",
       "48966                  0.0                            0.0                 0.0   \n",
       "48967                  0.0                            0.0                 0.0   \n",
       "48968                  0.0                            0.0                 0.0   \n",
       "\n",
       "       stat_volcanic activity_bin  stat_drought_bin  \\\n",
       "0                             0.0               0.0   \n",
       "1                             0.0               0.0   \n",
       "2                             0.0               0.0   \n",
       "3                             0.0               0.0   \n",
       "4                             0.0               0.0   \n",
       "...                           ...               ...   \n",
       "48964                         0.0               0.0   \n",
       "48965                         0.0               0.0   \n",
       "48966                         0.0               0.0   \n",
       "48967                         0.0               0.0   \n",
       "48968                         0.0               0.0   \n",
       "\n",
       "       stat_mass movement (dry)_bin  stat_lat  stat_lon  target_flood_1  \n",
       "0                               0.0       -46       168             0.0  \n",
       "1                               0.0       -46       168             0.0  \n",
       "2                               0.0       -46       168             0.0  \n",
       "3                               0.0       -46       168             0.0  \n",
       "4                               0.0       -46       168             0.0  \n",
       "...                             ...       ...       ...             ...  \n",
       "48964                           0.0        66       130             0.0  \n",
       "48965                           0.0        66       130             0.0  \n",
       "48966                           0.0        66       130             0.0  \n",
       "48967                           0.0        66       130             0.0  \n",
       "48968                           0.0        66       130             0.0  \n",
       "\n",
       "[48140 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_df_sub1 = attach_target(xy_df_sub1, y_master, 'flood', n_pred)\n",
    "\n",
    "xy_df_sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48970/48970 [00:03<00:00, 14097.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_directories(row, path):\n",
    "    '''\n",
    "    create directories that will be populated according to the dataset\n",
    "    '''\n",
    "    flood_target = row[f'target_flood_{n_pred}']\n",
    "\n",
    "    # Sanitize the row name to create a valid folder name\n",
    "    directory_name = f'extracted_{row.name}'\n",
    "    directory_name = directory_name.replace('/', '_').replace(' ', '_')\n",
    "\n",
    "    # Create the directory for this row, ensuring it's valid\n",
    "    if flood_target == 1:\n",
    "        output_dir = os.path.join(f'{path}/target_flood', directory_name)\n",
    "    else:\n",
    "        output_dir = os.path.join(f'{path}/no_flood_target', directory_name)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ensure directories are created before running the multithreaded execution\n",
    "path = f'data/era5/target_{n_pred}_redo'\n",
    "for _, row in tqdm(xy_df_sub1.iterrows(), total=len(xy_df_sub1)):\n",
    "    create_directories(row, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Earth Engine ImageCollection\n",
    "IC = ee.ImageCollection('ECMWF/ERA5_LAND/MONTHLY_AGGR').select(variables_to_extract)\n",
    "\n",
    "def process_grid_point(args):\n",
    "    '''\n",
    "    process entries of xy_df_sub1 and populate appropriate directories with raw era5 data\n",
    "    '''\n",
    "    index, row = args\n",
    "    # latitude_to_extract = row['stat_latitude']\n",
    "    # longitude_to_extract = row['stat_longitude']\n",
    "    lat, lon = row['grid_id'].split(', ')\n",
    "    latitude_to_extract = float(lat[1:])\n",
    "    longitude_to_extract = float(lon[:-1])\n",
    "\n",
    "    year_to_process = int(row['year'])\n",
    "    grid_id = row['grid_id']\n",
    "    flood_target = row[f'target_flood_{n_pred}']\n",
    "    point = ee.Geometry.Point(longitude_to_extract, latitude_to_extract)\n",
    "\n",
    "    # Create the output directory\n",
    "    output_dir = f'{path}/target_flood/extracted_{index}' if flood_target == 1 else f'{path}/no_flood_target/extracted_{index}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define the date range for the entire period (5 years)\n",
    "    start_date = datetime(year_to_process - 4, 1, 1)\n",
    "    end_date = datetime(year_to_process, 12, 31)\n",
    "\n",
    "    # Filter the ImageCollection for the entire date range\n",
    "    era5_tp = IC.filterDate(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Extract the time series for the entire period\n",
    "    try:\n",
    "        time_series = era5_tp.getRegion(point, scale=100000).getInfo()\n",
    "        time_series_df = pd.DataFrame(time_series[1:], columns=time_series[0])\n",
    "\n",
    "        # Convert the time column to a readable date format\n",
    "        time_series_df['time'] = pd.to_datetime(time_series_df['time'], unit='ms')\n",
    "\n",
    "        # Melt the DataFrame to the desired format\n",
    "        melted_df = time_series_df.melt(\n",
    "            id_vars=['time'],\n",
    "            value_vars=variables_to_extract,\n",
    "            var_name='id',\n",
    "            value_name='value'\n",
    "        )\n",
    "\n",
    "        # Sort by variable name (id) and then by time\n",
    "        melted_df = melted_df.sort_values(by=['id', 'time'])\n",
    "\n",
    "        # Save the entire melted DataFrame to a single CSV file\n",
    "        output_file = os.path.join(output_dir, f'era5_data.csv')\n",
    "        melted_df.to_csv(output_file, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process grid point {grid_id, row.name, point, longitude_to_extract, latitude_to_extract}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48970/48970 [17:35<00:00, 46.38it/s]\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "\tlist(tqdm(executor.map(process_grid_point, [(index, row) for index, row in xy_df_sub1.iterrows()]), total=len(xy_df_sub1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_dir(xy_df_sub1, path):\n",
    "\t'''\n",
    "\tread directories and flatten weather vars\n",
    "\t'''\n",
    "\tdirectories = sorted([f for f in os.listdir(path) if not f.startswith('.')])\n",
    "\tnum_features = 480\n",
    "\n",
    "\t# Create column names for the new features\n",
    "\tcolumn_names = [f'era_{i}' for i in range(num_features)]\n",
    "\n",
    "\t# Create an empty list to store the rows of data\n",
    "\tdata = []\n",
    "\n",
    "\t# Loop through directories and process each one\n",
    "\tfor directory in tqdm(directories):\n",
    "\t\t# Extract index from directory name\n",
    "\t\tidx = int(directory.split('_')[1])\n",
    "\n",
    "\t\t# Read and flatten features\n",
    "\t\tfeatures_df = pd.read_csv(f'{path}/{directory}/era5_data.csv')\n",
    "\t\tvalues = list(features_df['value'])\n",
    "\n",
    "\t\t# Gather the entire row's data (keep all existing columns)\n",
    "\t\trow_data = xy_df_sub1.loc[idx].values  # All columns in that row\n",
    "\n",
    "\t\t# Append the original row data + the new flattened feature values\n",
    "\t\tdata.append(list(row_data) + list(values))\n",
    "\n",
    "\t# Create a new DataFrame with all original columns and the new features\n",
    "\treturn pd.DataFrame(data, columns=xy_df_sub1.columns.tolist() + column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37304/37304 [00:26<00:00, 1434.22it/s]\n",
      "100%|██████████| 11666/11666 [00:07<00:00, 1583.22it/s]\n"
     ]
    }
   ],
   "source": [
    "xy_df_sub_new_no_flood = populate_dir(xy_df_sub1, f'{path}/no_flood_target')\n",
    "xy_df_sub_new_flood = populate_dir(xy_df_sub1, f'{path}/target_flood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_df_sub1_new_combined = pd.concat([xy_df_sub_new_no_flood, xy_df_sub_new_flood], axis=0)\n",
    "xy_df_sub1_new_combined.to_csv('data/xy_df_renamed/xy_df_sub5_full.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
