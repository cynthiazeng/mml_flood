{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youngoh/Desktop/flood_urop_repo/mml_flood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youngoh/Desktop/flood_urop_repo/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline(y_test, results):\n",
    "\ty_base = np.zeros(len(y_test)) \n",
    "\tprint('Dumb baseline AUC', metrics.roc_auc_score(y_test,y_base))\n",
    "\tresults['base1']=utils.get_scores_clf(y_test,y_base)\n",
    "\n",
    "def stats_only(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train.iloc[:, :21], np.ravel(y_train), x_test.iloc[:, :21])\n",
    "\tresults['stats only'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def nlp_only(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train.iloc[:, 25:153], np.ravel(y_train), x_test.iloc[:, 25:153])\n",
    "\tresults['nlp only'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def weather_only(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train.iloc[:, 153:], np.ravel(y_train), x_test.iloc[:, 153:])\n",
    "\tresults['weather only'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    " \n",
    "def stats_nlp(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train.iloc[:, :153], np.ravel(y_train), x_test.iloc[:, :153])\n",
    "\tresults['stats nlp'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def weather_nlp(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train.iloc[:, 25:], np.ravel(y_train), x_test.iloc[:, 25:])\n",
    "\tresults['weather nlp'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    " \n",
    "def stats_weather(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train.drop(columns=x_train.columns[25:25+128]), np.ravel(y_train), x_test.drop(columns=x_train.columns[25:25+128]))\n",
    "\tresults['stats weather'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def all_vars(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['all vars'] = utils.get_scores_clf(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline(y_test, results):\n",
    "\ty_base = np.zeros(len(y_test)) \n",
    "\tprint('Dumb baseline AUC', metrics.roc_auc_score(y_test,y_base))\n",
    "\tresults['base1']=utils.get_scores_clf(y_test,y_base)\n",
    "\n",
    "def stats_only(x_train, y_train, x_test, y_test, results):\n",
    "\tx_train, x_test = x_train.filter(regex='stat'), x_test.filter(regex='stat')\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['stats only'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def nlp_only(x_train, y_train, x_test, y_test, results):\n",
    "\tx_train, x_test = x_train.filter(regex='nlp'), x_test.filter(regex='nlp')\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['nlp only'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def weather_only(x_train, y_train, x_test, y_test, results):\n",
    "\tx_train, x_test = x_train.filter(regex='era'), x_test.filter(regex='era')\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['weather only'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    " \n",
    "def stats_nlp(x_train, y_train, x_test, y_test, results):\n",
    "\tx_train, x_test = x_train.filter(regex='stat|nlp'), x_test.filter(regex='stat|nlp')\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['stats nlp'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def weather_nlp(x_train, y_train, x_test, y_test, results):\n",
    "\tx_train, x_test = x_train.filter(regex='weather|nlp'), x_test.filter(regex='weather|nlp')\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['weather nlp'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    " \n",
    "def stats_weather(x_train, y_train, x_test, y_test, results):\n",
    "\tx_train, x_test = x_train.filter(regex='stat|era'), x_test.filter(regex='stat|era')\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['stats weather'] = utils.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "def all_vars(x_train, y_train, x_test, y_test, results):\n",
    "\ty_pred, y_pred_prob = utils.run_xgb(x_train, np.ravel(y_train), x_test)\n",
    "\tresults['all vars'] = utils.get_scores_clf(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39840, 539) (9130, 539) (39840, 1) (9130, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "xy_df_sub1 = pd.read_csv('data/xy_df_renamed/xy_df_sub1_full.csv')\n",
    "x = xy_df_sub1.drop(xy_df_sub1.filter(regex='target').columns, axis=1)  # Drop target columns\n",
    "# x = x.drop(x.filter(regex='flood'), axis=1)\n",
    "x = x.select_dtypes(['number'])  # Keep only numerical columns\n",
    "y = xy_df_sub1.filter(regex='target')  # Keep only target columns\n",
    "\n",
    "column_index = x.columns.get_loc('year')\n",
    "x = x.iloc[:, column_index+1:]\n",
    "\n",
    "# Get the 'year' column\n",
    "years = xy_df_sub1['year']\n",
    "\n",
    "# Determine the split based on years\n",
    "min_year, max_year = years.min(), years.max()\n",
    "unique_years = np.sort(years.unique())\n",
    "split_year = unique_years[int(len(unique_years) * 0.8)]  # 80% split point\n",
    "\n",
    "# Split data chronologically\n",
    "train_mask = years <= split_year\n",
    "test_mask = years > split_year\n",
    "\n",
    "x_train1, x_test1 = x[train_mask], x[test_mask]\n",
    "y_train1, y_test1 = y[train_mask], y[test_mask]\n",
    "\n",
    "print(x_train1.shape, x_test1.shape, y_train1.shape, y_test1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stat_flood_amt', 'stat_storm_amt', 'stat_earthquake_amt',\n",
       "       'stat_extreme temperature _amt', 'stat_landslide_amt',\n",
       "       'stat_volcanic activity_amt', 'stat_drought_amt',\n",
       "       'stat_mass movement (dry)_amt', 'stat_flood_ct', 'stat_storm_ct',\n",
       "       'stat_earthquake_ct', 'stat_extreme temperature _ct',\n",
       "       'stat_landslide_ct', 'stat_volcanic activity_ct', 'stat_drought_ct',\n",
       "       'stat_mass movement (dry)_ct', 'stat_flood_bin', 'stat_storm_bin',\n",
       "       'stat_earthquake_bin', 'stat_extreme temperature _bin',\n",
       "       'stat_landslide_bin', 'stat_volcanic activity_bin', 'stat_drought_bin',\n",
       "       'stat_mass movement (dry)_bin', 'stat_lat', 'stat_lon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.filter(regex='stat').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.657076746401628\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5375003577155317 0.5\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5491766259491582 0.5130012001358629 0.8076670317634173 0.5415139367070698 0.1192665256149098 0.20307692307692307\n",
      "[[7176  979]\n",
      " [ 777  198]]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "y_pred, y_pred_prob = utils.run_xgb(x_train1.filter(regex='stat'), y_train1, x_test1.filter(regex='stat'))\n",
    "results['stats only chrono split'] = utils.get_scores_clf(y_test1, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumb baseline AUC 0.5\n",
      "maximum f1 score, thres 0.47179635522129015 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5 0.47179635522129015 0.8932092004381161 0.5 0.10679079956188389 0.0\n",
      "[[8155    0]\n",
      " [ 975    0]]\n"
     ]
    }
   ],
   "source": [
    "baseline(y_test1, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.657076746401628\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5375003577155317 0.5\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5491766259491582 0.5130012001358629 0.8076670317634173 0.5415139367070698 0.1192665256149098 0.20307692307692307\n",
      "[[7176  979]\n",
      " [ 777  198]]\n"
     ]
    }
   ],
   "source": [
    "stats_only(x_train1, y_train1, x_test1, y_test1, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6874800067310671\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 20}\n",
      "maximum f1 score, thres 0.5269829350145094 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.4956670282507193 0.5233710143560297 0.8050383351588171 0.5296577528337185 0.11481824734836782 0.1794871794871795\n",
      "[[7175  980]\n",
      " [ 800  175]]\n"
     ]
    }
   ],
   "source": [
    "nlp_only(x_train1, y_train1, x_test1, y_test1, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.895953583647672\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.508646254471562 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5099862598060023 0.47164351851851855 0.7772179627601314 0.5131814680312534 0.10969025703390922 0.17743589743589744\n",
      "[[6923 1232]\n",
      " [ 802  173]]\n"
     ]
    }
   ],
   "source": [
    "weather_only(x_train1, y_train1, x_test1, y_test1, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.7068831097697108\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5423238542423087 0.5\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5136236696065023 0.5102763973771379 0.8286966046002191 0.5415466364822588 0.12047331216199615 0.1764102564102564\n",
      "[[7394  761]\n",
      " [ 803  172]]\n"
     ]
    }
   ],
   "source": [
    "stats_nlp(x_train1, y_train1, x_test1, y_test1, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6874800067310671\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 20}\n",
      "maximum f1 score, thres 0.5269829350145094 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.4956670282507193 0.5233710143560297 0.8050383351588171 0.5296577528337185 0.11481824734836782 0.1794871794871795\n",
      "[[7175  980]\n",
      " [ 800  175]]\n"
     ]
    }
   ],
   "source": [
    "weather_nlp(x_train1, y_train1, x_test1, y_test1, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.8627358216483783\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5331306369170259 0.5\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5267770284079297 0.4935887915489241 0.831763417305586 0.5315241553868163 0.11642976599007052 0.14974358974358976\n",
      "[[7448  707]\n",
      " [ 829  146]]\n"
     ]
    }
   ],
   "source": [
    "stats_weather(x_train1, y_train1, x_test1, y_test1, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.8659603154958664\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5357186321041743 0.5\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5313803392601676 0.4976199255465445 0.8328587075575027 0.5339433099089752 0.11747886420489878 0.15384615384615385\n",
      "[[7454  701]\n",
      " [ 825  150]]\n"
     ]
    }
   ],
   "source": [
    "all_vars(x_train1, y_train1, x_test1, y_test1, results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39840, 539) (9130, 539) (39840, 1) (9130, 1)\n"
     ]
    }
   ],
   "source": [
    "xy_df_sub2 = pd.read_csv('data/xy_df_renamed/xy_df_sub2_full.csv')\n",
    "x = xy_df_sub2.drop(xy_df_sub2.filter(regex='target').columns, axis=1)  # Drop target columns\n",
    "# x = x.drop(x.filter(regex='flood'), axis=1)\n",
    "x = x.select_dtypes(['number'])  # Keep only numerical columns\n",
    "y = xy_df_sub2.filter(regex='target')  # Keep only target columns\n",
    "\n",
    "column_index = x.columns.get_loc('year')\n",
    "x = x.iloc[:, column_index+1:]\n",
    "\n",
    "# Get the 'year' column\n",
    "years = xy_df_sub2['year']\n",
    "\n",
    "# Determine the split based on years\n",
    "min_year, max_year = years.min(), years.max()\n",
    "unique_years = np.sort(years.unique())\n",
    "split_year = unique_years[int(len(unique_years) * 0.8)]  # 80% split point\n",
    "\n",
    "# Split data chronologically\n",
    "train_mask = years <= split_year\n",
    "test_mask = years > split_year\n",
    "\n",
    "x_train2, x_test2 = x[train_mask], x[test_mask]\n",
    "y_train2, y_test2 = y[train_mask], y[test_mask]\n",
    "\n",
    "print(x_train2.shape, x_test2.shape, y_train2.shape, y_test2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumb baseline AUC 0.5\n",
      "maximum f1 score, thres 0.4487047883581909 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5 0.4487047883581909 0.8139101861993429 0.5 0.18608981380065717 0.0\n",
      "[[7431    0]\n",
      " [1699    0]]\n"
     ]
    }
   ],
   "source": [
    "results2 = {}\n",
    "\n",
    "baseline(y_test2, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6552563371295496\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 20}\n",
      "maximum f1 score, thres 0.5378351895401636 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5252114232179924 0.5378351895401636 0.7001095290251916 0.5415496493579661 0.2025217606360067 0.28899352560329605\n",
      "[[5901 1530]\n",
      " [1208  491]]\n"
     ]
    }
   ],
   "source": [
    "stats_only(x_train2, y_train2, x_test2, y_test2, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.681419150789009\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.52742323015734 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.48476194843848475 0.5053903245029525 0.7499452354874042 0.52676362776904 0.1969627264505936 0.17127722189523248\n",
      "[[6556  875]\n",
      " [1408  291]]\n"
     ]
    }
   ],
   "source": [
    "nlp_only(x_train2, y_train2, x_test2, y_test2, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.82386749603097\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.506001317587967 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5139878999805865 0.45936593098667605 0.7600219058050384 0.5113884306148249 0.1902001199040897 0.1153619776339023\n",
      "[[6743  688]\n",
      " [1503  196]]\n"
     ]
    }
   ],
   "source": [
    "weather_only(x_train2, y_train2, x_test2, y_test2, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.681419150789009\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.52742323015734 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.48476194843848475 0.5053903245029525 0.7499452354874042 0.52676362776904 0.1969627264505936 0.17127722189523248\n",
      "[[6556  875]\n",
      " [1408  291]]\n"
     ]
    }
   ],
   "source": [
    "weather_nlp(x_train2, y_train2, x_test2, y_test2, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6970444066369286\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5410778010484428 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.49987394327994117 0.5259437307505268 0.7349397590361446 0.5395649787739176 0.20278254275917515 0.22836962919364331\n",
      "[[6322 1109]\n",
      " [1311  388]]\n"
     ]
    }
   ],
   "source": [
    "stats_nlp(x_train2, y_train2, x_test2, y_test2, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.8119334373944899\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5330339295336427 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5221162020389427 0.5209816668709053 0.7421686746987952 0.5315205561164676 0.19902407915325024 0.19599764567392583\n",
      "[[6443  988]\n",
      " [1366  333]]\n"
     ]
    }
   ],
   "source": [
    "stats_weather(x_train2, y_train2, x_test2, y_test2, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.81315465717013\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5343750321670836 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5224726696912358 0.5175477739100136 0.7373493975903614 0.5328730817537433 0.19951535778366453 0.20718069452619187\n",
      "[[6380 1051]\n",
      " [1347  352]]\n"
     ]
    }
   ],
   "source": [
    "all_vars(x_train2, y_train2, x_test2, y_test2, results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39840, 539) (9130, 539) (39840, 1) (9130, 1)\n"
     ]
    }
   ],
   "source": [
    "# xy_df_sub5 = pd.read_csv('data/xy_df/xy_df_sub_5_combined.csv')\n",
    "# xy_df_sub5 = xy_df_sub5.drop([ 'latitude', 'longitude', 'Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month', 'End Day', 'label', 'Unnamed: 0'], axis=1)\n",
    "# x = xy_df_sub5.drop(xy_df_sub5.filter(regex='target').columns, axis=1)#drop target col\n",
    "# x = x.select_dtypes(['number'])#drop index col\n",
    "# y = xy_df_sub5.filter(regex='target') #filter to cols containing target\n",
    "\n",
    "# column_index = x.columns.get_loc('year')\n",
    "# x = x.iloc[:, column_index+1:]\n",
    "# x_train5, x_test5, y_train5, y_test5 = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# print(x_train5.shape, x_test5.shape, y_train5.shape, y_test5.shape)\n",
    "\n",
    "xy_df_sub5 = pd.read_csv('data/xy_df_renamed/xy_df_sub5_full.csv')\n",
    "x = xy_df_sub5.drop(xy_df_sub5.filter(regex='target').columns, axis=1)  # Drop target columns\n",
    "# x = x.drop(x.filter(regex='flood'), axis=1)\n",
    "x = x.select_dtypes(['number'])  # Keep only numerical columns\n",
    "y = xy_df_sub5.filter(regex='target')  # Keep only target columns\n",
    "\n",
    "column_index = x.columns.get_loc('year')\n",
    "x = x.iloc[:, column_index+1:]\n",
    "\n",
    "# Get the 'year' column\n",
    "years = xy_df_sub5['year']\n",
    "\n",
    "# Determine the split based on years\n",
    "min_year, max_year = years.min(), years.max()\n",
    "unique_years = np.sort(years.unique())\n",
    "split_year = unique_years[int(len(unique_years) * 0.8)]  # 80% split point\n",
    "\n",
    "# Split data chronologically\n",
    "train_mask = years <= split_year\n",
    "test_mask = years > split_year\n",
    "\n",
    "x_train5, x_test5 = x[train_mask], x[test_mask]\n",
    "y_train5, y_test5 = y[train_mask], y[test_mask]\n",
    "\n",
    "print(x_train5.shape, x_test5.shape, y_train5.shape, y_test5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumb baseline AUC 0.5\n",
      "maximum f1 score, thres 0.4040080945231412 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5 0.4040080945231412 0.6778751369112815 0.5 0.3221248630887185 0.0\n",
      "[[6189    0]\n",
      " [2941    0]]\n"
     ]
    }
   ],
   "source": [
    "baseline(y_test5, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6753378146601917\n",
      "{'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.46235076637902717 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.4876440300103577 0.46235076637902717 0.4704271631982475 0.488670656481108 0.3173139558307673 0.5399523971438286\n",
      "[[2707 3482]\n",
      " [1353 1588]]\n"
     ]
    }
   ],
   "source": [
    "stats_only(x_train5, y_train5, x_test5, y_test5, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6705521922326225\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 65}\n",
      "maximum f1 score, thres 0.2463803121376415 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.45561618492714673 0.2463803121376415 0.31883899233296825 0.49133082578588577 0.31838389428736386 0.9761985719143148\n",
      "[[  40 6149]\n",
      " [  70 2871]]\n"
     ]
    }
   ],
   "source": [
    "nlp_only(x_train5, y_train5, x_test5, y_test5, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.7573744170230869\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 20}\n",
      "maximum f1 score, thres 0.31419849935795013 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.507322635189425 0.31419849935795013 0.3502738225629792 0.49444224045590096 0.3197178323719675 0.8996939816388984\n",
      "[[ 552 5637]\n",
      " [ 295 2646]]\n"
     ]
    }
   ],
   "source": [
    "weather_only(x_train5, y_train5, x_test5, y_test5, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6705521922326225\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 65}\n",
      "maximum f1 score, thres 0.2463803121376415 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.45561618492714673 0.2463803121376415 0.31883899233296825 0.49133082578588577 0.31838389428736386 0.9761985719143148\n",
      "[[  40 6149]\n",
      " [  70 2871]]\n"
     ]
    }
   ],
   "source": [
    "weather_nlp(x_train5, y_train5, x_test5, y_test5, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.6843352974247028\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.45318379367902445 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.47688726568383244 0.45318379367902445 0.46341730558598027 0.4748456873804414 0.3118318423120624 0.5069704182250935\n",
      "[[2740 3449]\n",
      " [1450 1491]]\n"
     ]
    }
   ],
   "source": [
    "stats_nlp(x_train5, y_train5, x_test5, y_test5, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.756860532629901\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.45770787088136816 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.515506254337128 0.45770787088136816 0.45870755750273823 0.507685015956346 0.32553614319922475 0.6453587215232914\n",
      "[[2290 3899]\n",
      " [1043 1898]]\n"
     ]
    }
   ],
   "source": [
    "stats_weather(x_train5, y_train5, x_test5, y_test5, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n",
      "[10, 20, 65]\n",
      "Train AUC:  0.7653933577582377\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.44864143042058113 0.7\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.4934142130285775 0.44864143042058113 0.45312157721796276 0.482062371795305 0.3146152673398642 0.5634138048282897\n",
      "[[2480 3709]\n",
      " [1284 1657]]\n"
     ]
    }
   ],
   "source": [
    "all_vars(x_train5, y_train5, x_test5, y_test5, results5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
