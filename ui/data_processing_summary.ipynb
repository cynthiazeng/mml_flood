{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing for UI\n",
        "\n",
        " 1. grid_id (Grid ID)\n",
        " 2. central_lat (Central Latitude)\n",
        " 3. central_lon (Central Longitude)\n",
        " 4. total_event_count (Total Event Count)\n",
        " 5. total_flood_event (Total Flood Events)\n",
        " 6. earliest_event_year (Earliest Event Year)\n",
        " 7. latest_event_year (Latest Event Year)\n",
        " 8. total_damages (Total Damages)\n",
        " 9. primary_admin1 (Primary Administrative Region)\n",
        " 10. event_summary (Event Summary)"
      ],
      "metadata": {
        "id": "ujcxd7FAkOSY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "58rIpyAykG-b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "%cd drive/My Drive/mml_flood/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN1ock8JkXZf",
        "outputId": "85ad4122-58b6-4873-e3b5-48bb5718fd6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/mml_flood\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read data"
      ],
      "metadata": {
        "id": "0362MQyHk89I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gdis data - geocoded disasters\n",
        "gdis = pd.read_csv('data/disaster/pend-gdis-1960-2018-disasterlocations.csv')\n",
        "# #emdat data - international disasters\n",
        "emdat = pd.read_csv('data/disaster/emdat_public_2022_09_21_query_uid-47Yzpr.csv', skiprows=[0,1,2,3,4,5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IJRLo34k4Qi",
        "outputId": "996cc2c7-f55f-42e5-9942-76a404266477"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-53a980b4090f>:4: DtypeWarning: Columns (8,16,17,18,19,24,25,26,27,46,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  emdat = pd.read_csv('data/disaster/emdat_public_2022_09_21_query_uid-47Yzpr.csv', skiprows=[0,1,2,3,4,5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ## Filter emdat columns"
      ],
      "metadata": {
        "id": "-GQOBcwKu2pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emdat['disasterno'] = emdat['Dis No'].str[:-4]  # Remove last 4 characters \"-XYZ\" area code"
      ],
      "metadata": {
        "id": "Nd0AES0Avnlg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emdat_cols = ['disasterno', 'Year', 'Event Name',\n",
        "              'Start Year', 'Start Month', 'Start Day',\n",
        "              'End Year', 'End Month', 'End Day',\n",
        "              \"Total Damages, Adjusted ('000 US$)\",\n",
        "              'Total Deaths', 'Total Affected',\n",
        "              \"Reconstruction Costs, Adjusted ('000 US$)\",\n",
        "              'Disaster Subtype', 'OFDA Response', 'River Basin']\n",
        "\n",
        "# Subset EMDAT to available columns (ignore missing ones if not present)\n",
        "emdat = emdat[[col for col in emdat_cols if col in emdat.columns]]\n",
        "print(emdat['OFDA Response'].count())  # check available data\n",
        "print(emdat['River Basin'].count())    # check available data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4kP8k7auPpL",
        "outputId": "123780f8-f6ab-4227-ced5-0ed22ff76784"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1716\n",
            "1312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(emdat.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL2zzdoKln9Q",
        "outputId": "e8d8a826-aa9e-452d-80a7-1281c3a13e72"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['disasterno', 'Year', 'Event Name', 'Start Year', 'Start Month',\n",
            "       'Start Day', 'End Year', 'End Month', 'End Day',\n",
            "       'Total Damages, Adjusted ('000 US$)', 'Total Deaths', 'Total Affected',\n",
            "       'Reconstruction Costs, Adjusted ('000 US$)', 'Disaster Subtype',\n",
            "       'OFDA Response', 'River Basin'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gdis.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsYReP1imRD3",
        "outputId": "e601ef70-a14d-4510-b581-e0bda63ccda7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'country', 'iso3', 'gwno', 'year', 'geo_id', 'geolocation',\n",
            "       'level', 'adm1', 'adm2', 'adm3', 'location', 'historical',\n",
            "       'hist_country', 'disastertype', 'disasterno', 'latitude', 'longitude'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merged cleaned emdat with gdis on disasterno"
      ],
      "metadata": {
        "id": "r8lXxgctv5WB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(emdat, gdis, on='disasterno', how='right')\n",
        "merged_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czCBlQ9qv7s4",
        "outputId": "39a35578-ba71-4df5-a87a-7d0328522e23"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82885, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate records based on GDIS 'id'\n",
        "merged_df = merged_df.drop_duplicates(subset=['id'])\n",
        "print(\"Merged Data Shape:\", merged_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPJDv3F-wATd",
        "outputId": "3323a74c-4e92-49da-f636-9af507fdead7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged Data Shape: (9924, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flood_df = merged_df[merged_df['disastertype'].str.lower() == 'flood'].copy()\n",
        "print(\"Flood Events Shape:\", flood_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1MlQcTbyb-8",
        "outputId": "60dc2ac4-af37-452a-9269-fdf43178a040"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flood Events Shape: (4274, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Grid IDs and Compute Duration\n"
      ],
      "metadata": {
        "id": "kj5ubfPxwNWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create grid_id from GDIS coordinates\n",
        "flood_df['lat_grid'] = flood_df['latitude'].round().astype(int)\n",
        "flood_df['lon_grid'] = flood_df['longitude'].round().astype(int)\n",
        "flood_df['grid_id'] = flood_df['lat_grid'].astype(str) + \"_\" + flood_df['lon_grid'].astype(str)\n",
        "\n",
        "# Central coordinates for each grid cell\n",
        "flood_df['central_lat'] = flood_df['lat_grid']\n",
        "flood_df['central_lon'] = flood_df['lon_grid']\n"
      ],
      "metadata": {
        "id": "VTfvhM1CwOAM"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_duration(row):\n",
        "    try:\n",
        "        start_date = pd.Timestamp(year=int(row['Start Year']), month=int(row['Start Month']), day=int(row['Start Day']))\n",
        "        end_date = pd.Timestamp(year=int(row['End Year']), month=int(row['End Month']), day=int(row['End Day']))\n",
        "        return (end_date - start_date).days\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "flood_df['duration'] = flood_df.apply(compute_duration, axis=1)\n"
      ],
      "metadata": {
        "id": "67w4D7ZJwfWs"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flood_df['duration']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "zoxJLUQXyoeH",
        "outputId": "195aff4a-f2d9-42ac-e56d-2a7947dc8fca"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        12.0\n",
              "2         7.0\n",
              "3        46.0\n",
              "18       16.0\n",
              "27        0.0\n",
              "         ... \n",
              "82550     4.0\n",
              "82732     NaN\n",
              "82734     NaN\n",
              "82735     NaN\n",
              "82739     NaN\n",
              "Name: duration, Length: 4274, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82550</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82732</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82734</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82735</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82739</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4274 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregate Data by Grid Cell\n",
        "\n",
        "---\n",
        "Aggregate Data by Grid Cell (Flood Events Only):\n",
        "\n",
        "Group the data by grid_id and compute the following parameters:\n",
        "\n",
        "*total_event_count*: Count of flood events in the grid.\n",
        "\n",
        "*earliest_event_year*: Minimum of the 'year' column.\n",
        "\n",
        "*latest_event_year*: Maximum of the 'year' column.\n",
        "\n",
        "*total_damages*: Sum of \"Total Damages, Adjusted ('000 US$)\".\n",
        "\n",
        "*primary_admin1*: Most common administrative region (adm1).\n",
        "\n",
        "*unique_locations*: Comma-separated list of unique location names.\n",
        "\n",
        "*avg_duration*: Average duration (in days) of flood events.\n",
        "\n",
        "#Additional parameters (if available):\n",
        "\n",
        "\n",
        "*avg_damage_per_flood*: Total_damages divided by total_event_count.\n",
        "\n",
        "*total_deaths*: Sum of \"Total Deaths\".\n",
        "\n",
        "*total_affected*: Sum of \"Total Affected\".\n",
        "\n",
        "*reconstruction_costs*: Sum of \"Reconstruction Costs, Adjusted ('000 US$)\".\n",
        "\n",
        "*predominant_subtype*: Mode of \"Disaster Subtype\".\n",
        "\n",
        "*ofda_response_count*: Count of non-null \"OFDA Response\".\n",
        "\n",
        "*predominant_river_basin*: Mode of \"River Basin\".\n",
        "\n",
        "*flood_recurrence_interval*: (latest_event_year - earliest_event_year)divided by total_event_count.\n"
      ],
      "metadata": {
        "id": "BRLAkIa3xE4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_divide(numerator, denominator):\n",
        "    return numerator / denominator if denominator and denominator != 0 else np.nan"
      ],
      "metadata": {
        "id": "3sWHl8dgxG4Y"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate all params\n",
        "aggregated = flood_df.groupby('grid_id').agg(\n",
        "    total_event_count = ('disasterno', 'count'),\n",
        "    earliest_event_year = ('year', 'min'),\n",
        "    latest_event_year = ('year', 'max'),\n",
        "    total_damages = (\"Total Damages, Adjusted ('000 US$)\", 'sum'),\n",
        "    central_lat = ('central_lat', 'first'),\n",
        "    central_lon = ('central_lon', 'first'),\n",
        "    primary_admin1 = ('adm1', lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan),\n",
        "    unique_locations = ('location', lambda x: ', '.join(sorted(x.unique()))),\n",
        "    avg_duration = ('duration', 'mean'),\n",
        "    total_deaths = ('Total Deaths', 'sum') if 'Total Deaths' in flood_df.columns else (lambda x: np.nan),\n",
        "    total_affected = ('Total Affected', 'sum') if 'Total Affected' in flood_df.columns else (lambda x: np.nan),\n",
        "    reconstruction_costs = (\"Reconstruction Costs, Adjusted ('000 US$)\", 'sum') if \"Reconstruction Costs, Adjusted ('000 US$)\" in flood_df.columns else (lambda x: np.nan),\n",
        "    predominant_subtype = ('Disaster Subtype', lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan) if 'Disaster Subtype' in flood_df.columns else (lambda x: np.nan),\n",
        "    ofda_response_count = ('OFDA Response', lambda x: x.notnull().sum()) if 'OFDA Response' in flood_df.columns else (lambda x: np.nan),\n",
        "    predominant_river_basin = ('River Basin', lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan) if 'River Basin' in flood_df.columns else (lambda x: np.nan)\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "gffJs6P2zvK4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated['total_flood_event'] = aggregated['total_event_count']\n",
        "\n",
        "# Compute derived parameters:\n",
        "aggregated['avg_damage_per_flood'] = aggregated.apply(\n",
        "    lambda row: safe_divide(row['total_damages'], row['total_event_count']),\n",
        "    axis=1\n",
        ")\n",
        "# Flood recurrence formula last-first divided by number of events in the interval\n",
        "aggregated['flood_recurrence_interval'] = aggregated.apply(\n",
        "    lambda row: safe_divide(row['latest_event_year'] - row['earliest_event_year'], row['total_event_count']),\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "BgtSE08fz5ks"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text summary for events in each grid cell"
      ],
      "metadata": {
        "id": "XadP1so01qxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated['event_summary'] = aggregated.apply(\n",
        "    lambda row: f\"{row['total_event_count']} events ({row['total_flood_event']} floods) from {int(row['earliest_event_year'])} to {int(row['latest_event_year'])}, total damages: {row['total_damages'] if not pd.isna(row['total_damages']) else 'N/A'} ('000 US$)\",\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "WzclJkiB1uLl"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## There is a lot of missing data for $ costs; Replacing 0s with NaNs"
      ],
      "metadata": {
        "id": "eCmPKmi32Ee-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace zeros with NaN for cost-related columns in the aggregated DataFrame.\n",
        "# This assumes that a 0 value for damages or reconstruction costs should be treated as missing data.\n",
        "cost_columns = ['total_damages', 'reconstruction_costs']\n",
        "for col in cost_columns:\n",
        "    aggregated[col] = aggregated[col].replace(0, np.nan)\n",
        "\n",
        "# Recompute the derived parameter 'avg_damage_per_flood' after the replacement.\n",
        "aggregated['avg_damage_per_flood'] = aggregated.apply(\n",
        "    lambda row: safe_divide(row['total_damages'], row['total_event_count']),\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "Qgj4A-f72Jpe"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select and Order Final Columns\n",
        "\n",
        "## We now keep only the desired columns:\n",
        "\n",
        " 1. grid_id  \n",
        " 2. central_lat  \n",
        " 3. central_lon  \n",
        " 4. total_event_count  \n",
        " 5. earliest_event_year  \n",
        " 6. latest_event_year  \n",
        " 7. total_damages  \n",
        " 8. primary_admin1  \n",
        " 9. unique_locations  \n",
        " 10. avg_duration  \n",
        " 11. avg_damage_per_flood  \n",
        " 12. total_deaths  \n",
        " 13. total_affected  \n",
        " 14. reconstruction_costs  \n",
        " 15. predominant_subtype  \n",
        " 16. ofda_response_count  \n",
        " 17. predominant_river_basin  \n",
        " 18. flood_recurrence_interval\n",
        " 19. event_summary"
      ],
      "metadata": {
        "id": "VCvRDDqB0GkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_columns = ['grid_id', 'central_lat', 'central_lon', 'total_event_count',\n",
        "                 'earliest_event_year', 'latest_event_year',\n",
        "                 'total_damages', 'primary_admin1', 'unique_locations', 'avg_duration',\n",
        "                 'avg_damage_per_flood', 'total_deaths', 'total_affected',\n",
        "                 'reconstruction_costs', 'predominant_subtype', 'ofda_response_count',\n",
        "                 'predominant_river_basin', 'flood_recurrence_interval', 'event_summary']\n",
        "\n",
        "final_df = aggregated[final_columns].copy()\n"
      ],
      "metadata": {
        "id": "S8myWfW20I8F"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ds6iJxS13Jx",
        "outputId": "841a784e-38ae-4aba-896e-d6855c0c9ff9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   grid_id  central_lat  central_lon  total_event_count  earliest_event_year  \\\n",
            "0  -10_-36          -10          -36                  1                 2004   \n",
            "1  -10_-37          -10          -37                  5                 1967   \n",
            "2  -10_-66          -10          -66                  1                 1987   \n",
            "3  -10_124          -10          124                  1                 2010   \n",
            "4   -10_14          -10           14                  2                 2004   \n",
            "\n",
            "   latest_event_year  total_damages       primary_admin1  \\\n",
            "0               2004          531.0              Alagoas   \n",
            "1               2009       777910.0              Alagoas   \n",
            "2               1987            NaN                Pando   \n",
            "3               2010            NaN  Nusa Tenggara Timur   \n",
            "4               2005            NaN         Cuanza Norte   \n",
            "\n",
            "             unique_locations  avg_duration  avg_damage_per_flood  \\\n",
            "0                      Maceio           1.0                 531.0   \n",
            "1                     Alagoas           4.4              155582.0   \n",
            "2             Nueva Esperanza           NaN                   NaN   \n",
            "3                     Toianas           3.0                   NaN   \n",
            "4  Dondo area, Dondo district          30.5                   NaN   \n",
            "\n",
            "   total_deaths  total_affected  reconstruction_costs predominant_subtype  \\\n",
            "0          28.0          2254.0                   NaN      Riverine flood   \n",
            "1         451.0       2110149.0                   NaN      Riverine flood   \n",
            "2          25.0         20000.0                   NaN      Riverine flood   \n",
            "3          16.0           200.0                   NaN         Flash flood   \n",
            "4           1.0         12000.0                   NaN      Riverine flood   \n",
            "\n",
            "   ofda_response_count            predominant_river_basin  \\\n",
            "0                    0                                NaN   \n",
            "1                    3                                NaN   \n",
            "2                    0                                NaN   \n",
            "3                    0                                NaN   \n",
            "4                    0  Kapacala, Cuanza, Okavango rivers   \n",
            "\n",
            "   flood_recurrence_interval  \\\n",
            "0                        0.0   \n",
            "1                        8.4   \n",
            "2                        0.0   \n",
            "3                        0.0   \n",
            "4                        0.5   \n",
            "\n",
            "                                       event_summary  \n",
            "0  1 events (1 floods) from 2004 to 2004, total d...  \n",
            "1  5 events (5 floods) from 1967 to 2009, total d...  \n",
            "2  1 events (1 floods) from 1987 to 1987, total d...  \n",
            "3  1 events (1 floods) from 2010 to 2010, total d...  \n",
            "4  2 events (2 floods) from 2004 to 2005, total d...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data to csv"
      ],
      "metadata": {
        "id": "sU5RHS9Q3iZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('/content/drive/MyDrive/mml_flood/UI/flood_grid_summary.csv', index=False)\n",
        "print(\"Aggregated flood grid summary data saved to '/content/drive/MyDrive/mml_flood/UI/flood_grid_summary.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HDqMQni4F-Z",
        "outputId": "b6d31cc7-4c5d-480f-d017-43420c11d969"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated flood grid summary data saved to '/content/drive/MyDrive/mml_flood/UI/flood_grid_summary.csv'.\n"
          ]
        }
      ]
    }
  ]
}